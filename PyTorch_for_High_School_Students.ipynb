{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a7c1ccd",
   "metadata": {},
   "source": [
    "# PyTorch and Simple Neural Networks: Detailed Explanation for High School Students"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6884491c",
   "metadata": {},
   "source": [
    "## 1. Introduction to PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ca9f98",
   "metadata": {},
   "source": [
    "In this section, we'll learn about PyTorch, a popular deep learning library:\n",
    "- Tensors: the core data structure in PyTorch\n",
    "- Simple operations with tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee26b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch (uncomment the line below if you're running this in Google Colab)\n",
    "!pip install torch\n",
    "\n",
    "# Import PyTorch\n",
    "import torch\n",
    "\n",
    "# Create a tensor\n",
    "tensor = torch.tensor([[1, 2], [3, 4]])\n",
    "print('Tensor:', tensor)\n",
    "\n",
    "# Perform basic operations\n",
    "tensor_add = tensor + 2\n",
    "tensor_multiply = tensor * 2\n",
    "\n",
    "print('After adding 2:', tensor_add)\n",
    "print('After multiplying by 2:', tensor_multiply)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1463467e",
   "metadata": {},
   "source": [
    "## 2. Understanding the Architecture of a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb4ce55",
   "metadata": {},
   "source": [
    "A neural network is made up of layers that process the input data and produce an output. Here's a simple explanation of the architecture we'll be using:\n",
    "- **Input Layer**: This layer takes the input data. In this case, the input is a 28x28 image (flattened to a 784-length vector).\n",
    "- **Hidden Layer**: This layer transforms the input into a new representation. We will use 128 neurons in this layer, and apply the ReLU activation function to introduce non-linearity.\n",
    "- **Output Layer**: The final layer produces the network's output, which is a prediction for each class. In this case, we have 10 classes, corresponding to the digits 0-9.\n",
    "The goal of the network is to minimize the error between its predicted output and the actual labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3f66be",
   "metadata": {},
   "source": [
    "## 3. Building a Simple Neural Network in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd6683e",
   "metadata": {},
   "source": [
    "Now, we'll build a simple feedforward neural network using PyTorch. This network will take an input, pass it through a hidden layer, and output a result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc16906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules from PyTorch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the neural network class\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # Input layer (28*28 = 784) -> Hidden layer (128 neurons)\n",
    "        self.fc1 = nn.Linear(28*28, 128)  \n",
    "        # Hidden layer -> Output layer (10 classes)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply ReLU activation function on hidden layer\n",
    "        x = torch.relu(self.fc1(x))      \n",
    "        # Output layer without activation (we'll apply softmax later for classification)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the network\n",
    "model = SimpleNN()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce19de68",
   "metadata": {},
   "source": [
    "## 4. Training a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e490c0f",
   "metadata": {},
   "source": [
    "Next, we'll create a simple training loop where the neural network learns from data. We'll use a loss function and optimizer to train the model. Here's what each part of the code does:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c122a01",
   "metadata": {},
   "source": [
    "- **optimizer.zero_grad()**: Clears the gradients from the previous step to avoid accumulation.\n",
    "- **model(inputs)**: Performs a forward pass through the network, generating predictions.\n",
    "- **criterion(outputs, labels)**: Calculates the loss by comparing predictions to the actual labels.\n",
    "- **loss.backward()**: Performs backpropagation, calculating the gradient of the loss with respect to the model's parameters.\n",
    "- **optimizer.step()**: Updates the model's parameters using the calculated gradients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266030cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import optimizer and loss function\n",
    "import torch.optim as optim\n",
    "\n",
    "# Create dummy data for training (64 samples, 28x28 images flattened)\n",
    "inputs = torch.randn(64, 28*28)\n",
    "labels = torch.randint(0, 10, (64,))  # Random labels for 10 classes\n",
    "\n",
    "# Initialize loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5):\n",
    "    optimizer.zero_grad()  # Clear gradients\n",
    "    outputs = model(inputs)  # Forward pass\n",
    "    loss = criterion(outputs, labels)  # Calculate loss\n",
    "    loss.backward()  # Backpropagation\n",
    "    optimizer.step()  # Update weights\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ecde8d",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd38bab",
   "metadata": {},
   "source": [
    "In this notebook, we learned how to:\n",
    "- Use PyTorch to create tensors and perform operations on them\n",
    "- Build a simple neural network using PyTorch\n",
    "- Understand the architecture of a neural network (input, hidden, and output layers)\n",
    "- Train the network using a simple training loop\n",
    "These are the foundational skills for building and training deep learning models in PyTorch."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
